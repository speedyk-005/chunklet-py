# Key features

## SentenceSplitter
- Multilingual Support: Leverages language-specific algorithms and detection for broad coverage.
- Custom Splitters: Uses centralized registry for custom splitting logic.
- Fallback Mechanism: Employs a universal rule-based splitter for unsupported languages.

## PlainTextChunker
- Multiple Chunking Modes: Split text by sentence count, token count, or a hybrid approach.
- Clause-Level Overlap: Ensures semantic continuity between chunks by overlapping at natural clause boundaries with Customizable continuation marker.
- Multilingual Support: Leverages language-specific algorithms and detection for broad coverage.
- Pluggable Token Counters: Integrate custom token counting functions (e.g., for specific LLM tokenizers).
- Parallel Processing: Efficiently handles batch chunking of multiple texts using multiprocessing.
- Memory friendly batching: Yields chunks one at a time, reducing memory usage, especially for multiple texts processing.

## DocumentChunker
- Multi-Format Support: Chunks text from PDF, DOCX, TXT, MD, and RST files.
- Metadata Enrichment: Automatically adds source file path and other document-level metadata (e.g., PDF page numbers) to each chunk.
- Bulk Processing: Efficiently chunks multiple documents in a single call.
- Pluggable Token Counters: Integrate custom token counting functions (e.g., for specific LLM tokenizers).
- Pluggable Document processors: Integrate custom processors allowing definition of specific logic for extracting text from various file types.
- Memory friendly batching: Yields chunks one at a time, reducing memory usage, especially for very large documents.


## CodeChunker
- Language-Agnostic: Works across Python, C/C++, Java, C#, JavaScript, Go, PHP, Ruby, Lua, and others without requiring language-specific grammars.
- Structural analysis with namespace hierarchy tracking
- Configurable token limits with strict/lenient overflow handling
- Flexible docstring and comment processing modes
- Lline number preservation and source tracking
- Parallel batch processing for multiple files
- Comprehensive logging and progress tracking
- Pluggable Token Counters: Integrate custom token counting functions (e.g., for specific LLM tokenizers).
- Memory friendly batching: Yields chunks one at a time, reducing memory usage, especially for very large code files.
