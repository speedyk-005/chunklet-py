"""
chunklet/__init__.py

A smart sentence-based tokenizer for splitting multilingual or multi-format text
into overlapping chunks. Ideal for pre-processing tasks such as LLM prompting,
summarization, and context-aware NLP.
"""

from .core import Chunklet

__version__ = "1.0.1"
__author__ = "Speed k."
__license__ = "MIT"